import logging
import os
import asyncio
import signal
import re
import datetime
import pytz
import pickle
from collections import defaultdict
import psycopg2
from psycopg2 import pool
import io
import html
import time
from typing import Coroutine
import mimetypes
import json

import httpx 
import aiohttp
import aiohttp.web
from telegram import Update, Message, BotCommand, InlineKeyboardButton, InlineKeyboardMarkup
from telegram.constants import ChatAction, ParseMode
from telegram.ext import Application, CommandHandler, MessageHandler, ContextTypes, filters, BasePersistence, CallbackQueryHandler
from telegram.error import BadRequest

from google import genai
from google.genai import types

from youtube_transcript_api import YouTubeTranscriptApi

logging.basicConfig(format='%(asctime)s - %(name)s - %(levelname)s - %(message)s', level=logging.INFO)
logger = logging.getLogger(__name__)

try:
    with open('system_prompt.md', 'r', encoding='utf-8') as f:
        system_instruction_text = f.read()
    logger.info("–°–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω.")
except FileNotFoundError:
    logger.critical("–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: —Ñ–∞–π–ª system_prompt.md –Ω–µ –Ω–∞–π–¥–µ–Ω!")
    exit(1)

# --- –ë–ê–ó–ê –î–ê–ù–ù–´–• (–ù–ê–î–ï–ñ–ù–ê–Ø –í–ï–†–°–ò–Ø) ---
class PostgresPersistence(BasePersistence):
    def __init__(self, database_url: str):
        super().__init__()
        self.db_pool = None
        self.dsn = database_url
        try:
            self._connect()
            self._initialize_db()
        except psycopg2.Error as e:
            logger.critical(f"PostgresPersistence: –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ –ë–î: {e}")
            raise

    def _connect(self):
        if self.db_pool:
            try: self.db_pool.closeall()
            except Exception as e: logger.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–∫—Ä—ã—Ç–∏–∏ —Å—Ç–∞—Ä–æ–≥–æ –ø—É–ª–∞: {e}")
        dsn = self.dsn
        keepalive_options = "keepalives=1&keepalives_idle=60&keepalives_interval=10&keepalives_count=5"
        if "?" in dsn:
             if "keepalives" not in dsn: dsn = f"{dsn}&{keepalive_options}"
        else:
             dsn = f"{dsn}?{keepalive_options}"
        self.db_pool = psycopg2.pool.SimpleConnectionPool(1, 10, dsn=dsn)
        logger.info(f"–ü—É–ª —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π —Å –ë–î (–ø–µ—Ä–µ)—Å–æ–∑–¥–∞–Ω.")


    def _execute(self, query: str, params: tuple = None, fetch: str = None, retries=3):
        if not self.db_pool: raise ConnectionError("–ü—É–ª —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω.")
        last_exception = None
        for attempt in range(retries):
            conn = None
            connection_handled = False
            try:
                conn = self.db_pool.getconn()
                with conn.cursor() as cur:
                    cur.execute(query, params)
                    if fetch == "one": return cur.fetchone()
                    if fetch == "all": return cur.fetchall()
                    conn.commit()
                return True
            except (psycopg2.OperationalError, psycopg2.InterfaceError) as e:
                logger.warning(f"Postgres: –û—à–∏–±–∫–∞ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è (–ø–æ–ø—ã—Ç–∫–∞ {attempt + 1}/{retries}): {e}. –ü–æ–ø—ã—Ç–∫–∞ –ø–µ—Ä–µ–ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è...")
                last_exception = e
                if conn:
                    self.db_pool.putconn(conn, close=True)
                    connection_handled = True
                if attempt < retries - 1: self._connect(); time.sleep(1 + attempt)
                continue
            finally:
                if conn and not connection_handled:
                    self.db_pool.putconn(conn)
        
        logger.error(f"Postgres: –ù–µ —É–¥–∞–ª–æ—Å—å –≤—ã–ø–æ–ª–Ω–∏—Ç—å –∑–∞–ø—Ä–æ—Å –ø–æ—Å–ª–µ {retries} –ø–æ–ø—ã—Ç–æ–∫. –ü–æ—Å–ª–µ–¥–Ω—è—è –æ—à–∏–±–∫–∞: {last_exception}")
        return None

    def _initialize_db(self): self._execute("CREATE TABLE IF NOT EXISTS persistence_data (key TEXT PRIMARY KEY, data BYTEA NOT NULL);")
    def _get_pickled(self, key: str) -> object | None:
        res = self._execute("SELECT data FROM persistence_data WHERE key = %s;", (key,), fetch="one")
        return pickle.loads(res[0]) if res and res[0] else None
    def _set_pickled(self, key: str, data: object) -> None: self._execute("INSERT INTO persistence_data (key, data) VALUES (%s, %s) ON CONFLICT (key) DO UPDATE SET data = %s;", (key, pickle.dumps(data), pickle.dumps(data)))

    async def get_bot_data(self) -> dict: return await asyncio.to_thread(self._get_pickled, "bot_data") or {}
    async def update_bot_data(self, data: dict) -> None: await asyncio.to_thread(self._set_pickled, "bot_data", data)

    async def get_chat_data(self) -> defaultdict[int, dict]:
        all_data = await asyncio.to_thread(self._execute, "SELECT key, data FROM persistence_data WHERE key LIKE 'chat_data_%';", fetch="all")
        chat_data = defaultdict(dict)
        if all_data:
            for k, d in all_data:
                try: chat_data[int(k.split('_')[-1])] = pickle.loads(d)
                except (ValueError, IndexError): logger.warning(f"–û–±–Ω–∞—Ä—É–∂–µ–Ω –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π –∫–ª—é—á —á–∞—Ç–∞ –≤ –ë–î: '{k}'. –ó–∞–ø–∏—Å—å –ø—Ä–æ–ø—É—â–µ–Ω–∞.")
        return chat_data
    async def update_chat_data(self, chat_id: int, data: dict) -> None: await asyncio.to_thread(self._set_pickled, f"chat_data_{chat_id}", data)

    async def get_user_data(self) -> defaultdict[int, dict]:
        all_data = await asyncio.to_thread(self._execute, "SELECT key, data FROM persistence_data WHERE key LIKE 'user_data_%';", fetch="all")
        user_data = defaultdict(dict)
        if all_data:
            for k, d in all_data:
                try: user_data[int(k.split('_')[-1])] = pickle.loads(d)
                except (ValueError, IndexError): logger.warning(f"–û–±–Ω–∞—Ä—É–∂–µ–Ω –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π –∫–ª—é—á –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –≤ –ë–î: '{k}'. –ó–∞–ø–∏—Å—å –ø—Ä–æ–ø—É—â–µ–Ω–∞.")
        return user_data
    async def update_user_data(self, user_id: int, data: dict) -> None: await asyncio.to_thread(self._set_pickled, f"user_data_{user_id}", data)

    async def drop_chat_data(self, chat_id: int) -> None: await asyncio.to_thread(self._execute, "DELETE FROM persistence_data WHERE key = %s;", (f"chat_data_{chat_id}",))
    async def drop_user_data(self, user_id: int) -> None: await asyncio.to_thread(self._execute, "DELETE FROM persistence_data WHERE key = %s;", (f"user_data_{user_id}",))

    async def get_callback_data(self) -> dict | None: return None
    async def update_callback_data(self, data: dict) -> None: pass
    async def get_conversations(self, name: str) -> dict: return {}
    async def update_conversation(self, name: str, key: tuple, new_state: object | None) -> None: pass

    async def refresh_bot_data(self, bot_data: dict) -> None: data = await self.get_bot_data(); bot_data.update(data)
    async def refresh_chat_data(self, chat_id: int, chat_data: dict) -> None: data = await asyncio.to_thread(self._get_pickled, f"chat_data_{chat_id}") or {}; chat_data.update(data)
    async def refresh_user_data(self, user_id: int, user_data: dict) -> None: data = await asyncio.to_thread(self._get_pickled, f"user_data_{user_id}") or {}; user_data.update(data)
    async def flush(self) -> None: pass
    def close(self):
        if self.db_pool: self.db_pool.closeall()

# --- –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø –ë–û–¢–ê ---
TELEGRAM_BOT_TOKEN, GOOGLE_API_KEY, WEBHOOK_HOST, GEMINI_WEBHOOK_PATH, DATABASE_URL = map(os.getenv, ['TELEGRAM_BOT_TOKEN', 'GOOGLE_API_KEY', 'WEBHOOK_HOST', 'GEMINI_WEBHOOK_PATH', 'DATABASE_URL'])
if not all([TELEGRAM_BOT_TOKEN, GOOGLE_API_KEY, WEBHOOK_HOST, GEMINI_WEBHOOK_PATH]):
    logger.critical("–û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è!")
    exit(1)

DEFAULT_MODEL = 'gemini-2.5-flash'
MAX_HISTORY_MESSAGES = 100
MAX_OUTPUT_TOKENS = 8192
MAX_CONTEXT_CHARS = 100000 
USER_ID_PREFIX_FORMAT, TARGET_TIMEZONE = "[User {user_id}; Name: {user_name}]: ", "Europe/Moscow"

# --- –í–°–ü–û–ú–û–ì–ê–¢–ï–õ–¨–ù–´–ï –§–£–ù–ö–¶–ò–ò ---
def get_current_time_str() -> str: return datetime.datetime.now(pytz.timezone(TARGET_TIMEZONE)).strftime("%Y-%m-%d %H:%M:%S %Z")
def extract_youtube_id(url_text: str) -> str | None:
    match = re.search(r"(?:https?:\/\/)?(?:www\.)?(?:youtube\.com\/(?:[^\/\n\s]+\/\S+\/|(?:v|e(?:mbed)?)\/|\S*?[?&]v=)|youtu\.be\/)([a-zA-Z0-9_-]{11})", url_text)
    return match.group(1) if match else None
def extract_general_url(text: str) -> str | None:
    match = re.search(r'https?://[^\s<>"\'`]+', text)
    if match: return match.group(0).rstrip('.,?!')
    return None

# --- –§–£–ù–ö–¶–ò–ò-–í–ï–†–°–¢–ê–õ–¨–©–ò–ö–ò –î–õ–Ø TELEGRAM ---
def sanitize_telegram_html(raw_html: str) -> str:
    if not raw_html: return ""
    s = re.sub(r'<br\s*/?>', '\n', raw_html, flags=re.IGNORECASE)
    s = re.sub(r'<li>', '‚Ä¢ ', s, flags=re.IGNORECASE)
    s = re.sub(r'</?(?!b>|i>|u>|s>|code>|pre>|a>|tg-spoiler>)\w+\s*[^>]*>', '', s)
    return s.strip()

def html_safe_chunker(text: str, chunk_size: int = 4096) -> list[str]:
    chunks = []
    if not text: return ['']
    tag_stack = []
    remaining_text = text
    tag_regex = re.compile(r'</?(b|i|u|s|code|pre|a|tg-spoiler)>', re.IGNORECASE)

    while remaining_text:
        if len(remaining_text) <= chunk_size:
            chunks.append(remaining_text)
            break
        split_pos = remaining_text.rfind('\n', 0, chunk_size)
        if split_pos == -1: split_pos = chunk_size
        current_chunk = remaining_text[:split_pos]
        temp_stack = list(tag_stack)
        for match in tag_regex.finditer(current_chunk):
            tag_name = match.group(1).lower()
            if f'</{tag_name}>' == match.group(0).lower():
                if temp_stack and temp_stack[-1] == tag_name: temp_stack.pop()
            else:
                temp_stack.append(tag_name)
        closing_tags = ''.join(f'</{tag}>' for tag in reversed(temp_stack))
        chunks.append(current_chunk + closing_tags)
        tag_stack = temp_stack
        opening_tags = ''.join(f'<{tag}>' for tag in tag_stack)
        remaining_text = opening_tags + remaining_text[split_pos:].lstrip()
    return chunks

# --- –õ–û–ì–ò–ö–ê –ò–°–¢–û–†–ò–ò –ò –ö–û–ù–¢–ï–ö–°–¢–ê ---
async def _add_to_history(context: ContextTypes.DEFAULT_TYPE, role: str, parts: list, **kwargs):
    history = context.chat_data.setdefault("history", [])
    entry = {"role": role, "parts": parts, **kwargs}
    history.append(entry)
    while len(history) > MAX_HISTORY_MESSAGES:
        history.pop(0)

def build_context_for_model(chat_history: list) -> list:
    context_for_model = []
    current_chars = 0
    for entry in reversed(chat_history):
        if not all(k in entry for k in ('role', 'parts')):
            continue

        raw_parts = entry.get("parts", [])
        if not raw_parts:
            continue

        repaired_parts = [
            types.Part(text=p) if isinstance(p, str) else p 
            for p in raw_parts if p is not None and (isinstance(p, str) or hasattr(p, 'text') or hasattr(p, 'inline_data'))
        ]
        if not repaired_parts:
            continue
        
        # --- –ò–ó–ú–ï–ù–ï–ù–û: –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ô –§–ò–ö–° –ë–ê–ì–ê –° TypeError ---
        # –ö–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏—è `p.text or ''` —ç–ª–µ–≥–∞–Ω—Ç–Ω–æ –∑–∞–º–µ–Ω—è–µ—Ç None (—É –º–µ–¥–∏–∞-—Ñ–∞–π–ª–æ–≤) –Ω–∞ –ø—É—Å—Ç—É—é —Å—Ç—Ä–æ–∫—É,
        # –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–∞—è –ø–∞–¥–µ–Ω–∏–µ `"".join()`.
        entry_text = "".join(p.text or '' for p in repaired_parts)
        entry_chars = len(entry_text)
        
        if current_chars + entry_chars > MAX_CONTEXT_CHARS and context_for_model:
            logger.info(f"–ö–æ–Ω—Ç–µ–∫—Å—Ç –æ–±—Ä–µ–∑–∞–Ω. –£—á—Ç–µ–Ω–æ {len(context_for_model)} –∏–∑ {len(chat_history)} —Å–æ–æ–±—â–µ–Ω–∏–π.")
            break
        
        try:
            content_object = types.Content(role=entry["role"], parts=repaired_parts)
            context_for_model.insert(0, content_object)
            current_chars += entry_chars
        except Exception as e:
            logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å –∑–∞–ø–∏—Å—å –∏—Å—Ç–æ—Ä–∏–∏ –≤ Content: {e}. –ó–∞–ø–∏—Å—å: {entry}")
            
    return context_for_model

# --- –§–£–ù–ö–¶–ò–ò –û–¢–í–ï–¢–ê ---
async def stream_and_send_reply(message_to_edit: Message, stream: Coroutine) -> str:
    full_text, buffer, last_edit_time = "", "", time.time()
    try:
        async for chunk in stream:
            if text_part := getattr(chunk, 'text', ''): buffer += text_part
            current_time = time.time()
            if current_time - last_edit_time > 1.2 or len(buffer) > 150:
                new_text_portion = full_text + buffer
                sanitized_chunk = sanitize_telegram_html(new_text_portion)
                if sanitized_chunk != message_to_edit.text:
                    try:
                        await message_to_edit.edit_text(sanitized_chunk + " ‚ñå")
                        full_text, buffer, last_edit_time = new_text_portion, "", current_time
                    except BadRequest as e:
                        if "Message is not modified" not in str(e): logger.warning(f"–û—à–∏–±–∫–∞ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è: {e}")
        final_text = full_text + buffer
    except json.JSONDecodeError as e:
        logger.error(f"–û—à–∏–±–∫–∞ –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è JSON –≤ —Å—Ç—Ä–∏–º–µ: {e}", exc_info=False)
        final_text = full_text + buffer + "\n\n[‚ùóÔ∏è–û—Ç–≤–µ—Ç –±—ã–ª –ø—Ä–µ—Ä–≤–∞–Ω –∏–∑-–∑–∞ —Å–µ—Ç–µ–≤–æ–π –æ—à–∏–±–∫–∏.]"
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ —Å—Ç—Ä–∏–º–∏–Ω–≥–∞: {e}", exc_info=True)
        final_text = full_text + buffer + f"\n\n[‚ùå –û—à–∏–±–∫–∞ —Å—Ç—Ä–∏–º–∏–Ω–≥–∞: {str(e)[:100]}]"

    return final_text

async def send_final_reply(placeholder_message: Message, full_text: str, context: ContextTypes.DEFAULT_TYPE) -> Message:
    sanitized_text = sanitize_telegram_html(full_text)
    if not sanitized_text.strip(): sanitized_text = "ü§ñ –ú–æ–¥–µ–ª—å –Ω–µ –¥–∞–ª–∞ –æ—Ç–≤–µ—Ç–∞."

    chunks = html_safe_chunker(sanitized_text)

    sent_message = None
    try:
        await placeholder_message.edit_text(chunks[0])
        sent_message = placeholder_message

        if len(chunks) > 1:
            for chunk in chunks[1:]:
                sent_message = await context.bot.send_message(chat_id=placeholder_message.chat_id, text=chunk, parse_mode=ParseMode.HTML)
                await asyncio.sleep(0.1)
    except Exception as e:
        logger.error(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ —Ñ–∏–Ω–∞–ª—å–Ω–æ–π –æ—Ç–ø—Ä–∞–≤–∫–µ –æ—Ç–≤–µ—Ç–∞: {e}", exc_info=True)

    return sent_message or placeholder_message

# --- –ì–õ–ê–í–ù–´–ô –ü–†–û–¶–ï–°–°–û–† –ó–ê–ü–†–û–°–û–í ---
async def process_query(update: Update, context: ContextTypes.DEFAULT_TYPE, prompt_parts: list, content_type: str = None, content_id: str = None, tools: list = None):
    message = update.message
    logger.info(f"–ù–∞—á–∞–ª–æ process_query –¥–ª—è —á–∞—Ç–∞ {message.chat_id}. –¢–∏–ø –∫–æ–Ω—Ç–µ–Ω—Ç–∞: {content_type or 'text'}")
    
    user = update.effective_user
    await _add_to_history(context, "user", prompt_parts, user_id=user.id, message_id=message.message_id, content_type=content_type, content_id=content_id)
    client = context.bot_data['gemini_client']
    placeholder_message = await message.reply_text("...")

    try:
        context_for_model = build_context_for_model(context.chat_data.get("history", []))

        thinking_budget_mode = context.user_data.get('thinking_budget', 'auto')
        thinking_config_obj = None
        if thinking_budget_mode == 'max':
            logger.info("–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π –±—é–¥–∂–µ—Ç –º—ã—à–ª–µ–Ω–∏—è (24576).")
            thinking_config_obj = types.ThinkingConfig(budget=24576)

        final_tools = tools if tools is not None else [types.Tool(google_search=types.GoogleSearch())]

        request_config = types.GenerateContentConfig(
            temperature=1.0, 
            max_output_tokens=MAX_OUTPUT_TOKENS,
            system_instruction=system_instruction_text,
            tools=final_tools,
            thinking_config=thinking_config_obj
        )
        
        logger.info(f"–û—Ç–ø—Ä–∞–≤–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –∫ –º–æ–¥–µ–ª–∏ {DEFAULT_MODEL}...")
        stream = await client.generative_models.generate_content(
            model_name=f"models/{DEFAULT_MODEL}",
            contents=context_for_model,
            generation_config=request_config,
            stream=True
        )
        
        logger.info("–ù–∞—á–∞–ª–æ —Å—Ç—Ä–∏–º–∏–Ω–≥–∞ –æ—Ç–≤–µ—Ç–∞...")
        full_reply_text = await stream_and_send_reply(placeholder_message, stream)
        final_message = await send_final_reply(placeholder_message, full_reply_text, context)
        
        await _add_to_history(context, "model", [types.Part(text=full_reply_text)], bot_message_id=final_message.message_id)
        logger.info(f"–û—Ç–≤–µ—Ç —É—Å–ø–µ—à–Ω–æ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω –≤ —á–∞—Ç {message.chat_id}.")
    except Exception as e:
        logger.error(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –≤ process_query –¥–ª—è —á–∞—Ç–∞ {message.chat_id}: {e}", exc_info=True)
        await placeholder_message.edit_text(f"‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ —Å–µ—Ä—å–µ–∑–Ω–∞—è –æ—à–∏–±–∫–∞: {html.escape(str(e)[:500])}")

# --- –û–ë–†–ê–ë–û–¢–ß–ò–ö–ò –ö–û–ú–ê–ù–î ---
async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    logger.info(f"–ö–æ–º–∞–Ω–¥–∞ /start –æ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {update.effective_user.id} –≤ —á–∞—Ç–µ {update.effective_chat.id}")
    start_message = (
        "–Ø - –ñ–µ–Ω—è, –ª—É—á—à–∏–π –ò–ò-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –Ω–∞ –±–∞–∑–µ Google GEMINI 2.5 Flash:\n"
        "‚Ä¢ üí¨ –í–µ–¥—É –¥–∏–∞–ª–æ–≥, –ø–æ–Ω–∏–º–∞—é –∫–æ–Ω—Ç–µ–∫—Å—Ç, –∞–Ω–∞–ª–∏–∑–∏—Ä—É—é –¥–∞–Ω–Ω—ã–µ\n"
        "‚Ä¢ üé§ –ü–æ–Ω–∏–º–∞—é –≥–æ–ª–æ—Å–æ–≤—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è, –º–æ–≥—É –ø–µ—Ä–µ–≤–æ–¥–∏—Ç—å –≤ —Ç–µ–∫—Å—Ç\n"
        "‚Ä¢ üñº –ê–Ω–∞–ª–∏–∑–∏—Ä—É—é –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏ –≤–∏–¥–µ–æ (–¥–æ 20 –º–±)\n"
        "‚Ä¢ üìÑ –ß–∏—Ç–∞—é —Ä–µ–ø–æ—Å—Ç—ã, txt, pdf –∏ –≤–µ–±-—Å—Ç—Ä–∞–Ω–∏—Ü—ã\n"
        "‚Ä¢ üåê –ò—Å–ø–æ–ª—å–∑—É—é —É–º–Ω—ã–π Google-–ø–æ–∏—Å–∫ –∏ –æ–≥—Ä–æ–º–Ω—ã–π –æ–±—ä–µ–º —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã—Ö –∑–Ω–∞–Ω–∏–π\n\n"
        "<b>–ö–æ–º–∞–Ω–¥—ã:</b>\n"
        "/transcribe - <i>(–≤ –æ—Ç–≤–µ—Ç–µ –Ω–∞ –≥–æ–ª–æ—Å–æ–≤–æ–µ)</i> –†–∞—Å—à–∏—Ñ—Ä–æ–≤–∞—Ç—å –∞—É–¥–∏–æ\n"
        "/summarize_yt <i><—Å—Å—ã–ª–∫–∞></i> - –ö–æ–Ω—Å–ø–µ–∫—Ç –≤–∏–¥–µ–æ —Å YouTube\n"
        "/summarize_url <i><—Å—Å—ã–ª–∫–∞></i> - –í—ã–∂–∏–º–∫–∞ –∏–∑ —Å—Ç–∞—Ç—å–∏\n"
        "/thinking - –ù–∞—Å—Ç—Ä–æ–∏—Ç—å —Ä–µ–∂–∏–º —Ä–∞–∑–º—ã—à–ª–µ–Ω–∏–π\n"
        "/clear - –û—á–∏—Å—Ç–∏—Ç—å –∏—Å—Ç–æ—Ä–∏—é —á–∞—Ç–∞\n\n"
        "(!) –ü–æ–ª—å–∑—É—è—Å—å –±–æ—Ç–æ–º, –≤—ã –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å–æ–≥–ª–∞—à–∞–µ—Ç–µ—Å—å –Ω–∞ –æ—Ç–ø—Ä–∞–≤–∫—É —Å–æ–æ–±—â–µ–Ω–∏–π –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –æ—Ç–≤–µ—Ç–æ–≤ —á–µ—Ä–µ–∑ Google Gemini API."
    )
    await update.message.reply_text(start_message, parse_mode=ParseMode.HTML, disable_web_page_preview=True)

async def clear_history(update: Update, context: ContextTypes.DEFAULT_TYPE):
    logger.info(f"–ö–æ–º–∞–Ω–¥–∞ /clear –æ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {update.effective_user.id} –≤ —á–∞—Ç–µ {update.effective_chat.id}")
    context.chat_data.clear()
    await update.message.reply_text("üßπ –ò—Å—Ç–æ—Ä–∏—è —ç—Ç–æ–≥–æ —á–∞—Ç–∞ –æ—á–∏—â–µ–Ω–∞.")

async def thinking_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    logger.info(f"–ö–æ–º–∞–Ω–¥–∞ /thinking –æ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {update.effective_user.id}")
    current_mode = context.user_data.get('thinking_budget', 'auto')
    keyboard = [
        [InlineKeyboardButton(f"{'‚úÖ ' if current_mode == 'auto' else ''}–ê–≤—Ç–æ (–†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è)", callback_data="set_thinking_auto")],
        [InlineKeyboardButton(f"{'‚úÖ ' if current_mode == 'max' else ''}–ú–∞–∫—Å–∏–º—É–º (–ú–µ–¥–ª–µ–Ω–Ω–µ–µ)", callback_data="set_thinking_max")],
    ]
    await update.message.reply_text("–í—ã–±–µ—Ä–∏—Ç–µ —Ä–µ–∂–∏–º —Ä–∞–∑–º—ã—à–ª–µ–Ω–∏–π –º–æ–¥–µ–ª–∏:", reply_markup=InlineKeyboardMarkup(keyboard))

async def select_thinking_callback(update: Update, context: ContextTypes.DEFAULT_TYPE):
    query = update.callback_query
    await query.answer()
    choice = query.data.split('_')[-1]
    context.user_data['thinking_budget'] = choice
    logger.info(f"–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å {update.effective_user.id} —Å–º–µ–Ω–∏–ª —Ä–µ–∂–∏–º —Ä–∞–∑–º—ã—à–ª–µ–Ω–∏–π –Ω–∞: {choice}")
    text = "‚úÖ –†–µ–∂–∏–º —Ä–∞–∑–º—ã—à–ª–µ–Ω–∏–π —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –Ω–∞ <b>'–ê–≤—Ç–æ'</b>.\n–≠—Ç–æ –æ–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç –ª—É—á—à–∏–π –±–∞–ª–∞–Ω—Å —Å–∫–æ—Ä–æ—Å—Ç–∏ –∏ –∫–∞—á–µ—Å—Ç–≤–∞."
    if choice == 'max':
        text = "‚úÖ –†–µ–∂–∏–º —Ä–∞–∑–º—ã—à–ª–µ–Ω–∏–π —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –Ω–∞ <b>'–ú–∞–∫—Å–∏–º—É–º'</b>.\n–û—Ç–≤–µ—Ç—ã –º–æ–≥—É—Ç –±—ã—Ç—å –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–µ–µ, –Ω–æ –∏ –¥–æ–ª—å—à–µ."
    await query.edit_message_text(text, parse_mode=ParseMode.HTML)

async def transcribe_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    logger.info(f"–ö–æ–º–∞–Ω–¥–∞ /transcribe –æ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {update.effective_user.id}")
    replied_message = update.message.reply_to_message
    if not (replied_message and replied_message.voice):
        await update.message.reply_text("‚ÑπÔ∏è –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ —ç—Ç—É –∫–æ–º–∞–Ω–¥—É, –æ—Ç–≤–µ—á–∞—è –Ω–∞ –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ."); return
    await update.message.reply_text("üé§ –†–∞—Å—à–∏—Ñ—Ä–æ–≤—ã–≤–∞—é...")
    file_bytes = await (await replied_message.voice.get_file()).download_as_bytearray()
    client = context.bot_data['gemini_client']
    try:
        model = client.generative_models(DEFAULT_MODEL)
        response = await model.generate_content_async(
            contents=[types.Part(text="–†–∞—Å—à–∏—Ñ—Ä—É–π —ç—Ç–æ –∞—É–¥–∏–æ –∏ –≤–µ—Ä–Ω–∏ —Ç–æ–ª—å–∫–æ —Ç–µ–∫—Å—Ç."), types.Part(inline_data=types.Blob(mime_type=replied_message.voice.mime_type, data=file_bytes))]
        )
        await update.message.reply_text(f"<b>–¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç:</b>\n{html.escape(response.text)}", parse_mode=ParseMode.HTML)
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏: {e}", exc_info=True)
        await update.message.reply_text(f"‚ùå –û—à–∏–±–∫–∞ —Å–µ—Ä–≤–∏—Å–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è: {e}")
        
async def summarize_url_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    url = extract_general_url(" ".join(context.args))
    logger.info(f"–ö–æ–º–∞–Ω–¥–∞ /summarize_url –æ—Ç {update.effective_user.id}, URL: {url}")
    if not url:
        await update.message.reply_text("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —É–∫–∞–∂–∏—Ç–µ URL –ø–æ—Å–ª–µ –∫–æ–º–∞–Ω–¥—ã."); return
    await update.message.reply_text(f"üåê –ß–∏—Ç–∞—é —Å—Ç—Ä–∞–Ω–∏—Ü—É: {url}")
    prompt_text = f"–°–¥–µ–ª–∞–π –∫—Ä–∞—Ç–∫—É—é –≤—ã–∂–∏–º–∫—É (summary) –ø–æ —Ç–µ–∫—Å—Ç—É —Å –≤–µ–±-—Å—Ç—Ä–∞–Ω–∏—Ü—ã: {url}"
    prompt_parts = [types.Part(text=prompt_text)]
    url_tool = types.Tool(url_context=types.UrlContext())
    await process_query(update, context, prompt_parts, content_type="webpage", content_id=url, tools=[url_tool])

async def summarize_yt_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    video_id = extract_youtube_id(" ".join(context.args))
    logger.info(f"–ö–æ–º–∞–Ω–¥–∞ /summarize_yt –æ—Ç {update.effective_user.id}, video_id: {video_id}")
    if not video_id: await update.message.reply_text("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —É–∫–∞–∂–∏—Ç–µ —Å—Å—ã–ª–∫—É –Ω–∞ YouTube –ø–æ—Å–ª–µ –∫–æ–º–∞–Ω–¥—ã."); return
    await update.message.reply_text(f"üì∫ –ê–Ω–∞–ª–∏–∑–∏—Ä—É—é –≤–∏–¥–µ–æ —Å YouTube (ID: ...{video_id[-4:]})")
    try:
        transcript_list = await asyncio.to_thread(YouTubeTranscriptApi.get_transcript, video_id, languages=['ru', 'en'])
        transcript = " ".join([d['text'] for d in transcript_list])
    except Exception as e: await update.message.reply_text(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—É–±—Ç–∏—Ç—Ä–æ–≤: {e}"); return
    prompt = f"–°–¥–µ–ª–∞–π –∫—Ä–∞—Ç–∫–∏–π –∫–æ–Ω—Å–ø–µ–∫—Ç –ø–æ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç—É –≤–∏–¥–µ–æ —Å YouTube.\n\n–¢–†–ê–ù–°–ö–†–ò–ü–¢:\n{transcript}"
    await process_query(update, context, [types.Part(text=prompt)], content_type="youtube", content_id=video_id)

# --- –û–°–ù–û–í–ù–´–ï –û–ë–†–ê–ë–û–¢–ß–ò–ö–ò –°–û–û–ë–©–ï–ù–ò–ô ---
async def handle_text_and_replies(update: Update, context: ContextTypes.DEFAULT_TYPE):
    message, user = update.message, update.effective_user
    original_text = (message.text or "").strip()
    if not original_text: return
    logger.info(f"–ü–æ–ª—É—á–µ–Ω–æ —Ç–µ–∫—Å—Ç–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –æ—Ç {user.id} –≤ —á–∞—Ç–µ {message.chat_id}")

    if message.reply_to_message and message.reply_to_message.from_user.id == context.bot.id:
        history = context.chat_data.get("history", [])
        for i in range(len(history) - 1, -1, -1):
            if history[i].get("bot_message_id") == message.reply_to_message.message_id:
                prev_user_turn = history[i-1] if i > 0 else None
                if prev_user_turn and prev_user_turn.get("role") == "user":
                    content_type, content_id = prev_user_turn.get("content_type"), prev_user_turn.get("content_id")
                    if content_type and content_id:
                        logger.info(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—Ç–≤–µ—Ç–∞ –Ω–∞ —Å–æ–æ–±—â–µ–Ω–∏–µ —Å –∫–æ–Ω—Ç–µ–Ω—Ç–æ–º (—Ç–∏–ø: {content_type})")
                        prompt_text = f"–≠—Ç–æ —É—Ç–æ—á–Ω—è—é—â–∏–π –≤–æ–ø—Ä–æ—Å –∫ –ø—Ä–µ–¥—ã–¥—É—â–µ–º—É –∫–æ–Ω—Ç–µ–Ω—Ç—É. –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —Å–ø—Ä–∞—à–∏–≤–∞–µ—Ç: '{original_text}'. –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –∏—Å—Ö–æ–¥–Ω—ã–π –º–∞—Ç–µ—Ä–∏–∞–ª –µ—â–µ —Ä–∞–∑ –∏ –æ—Ç–≤–µ—Ç—å."
                        parts = [types.Part(text=prompt_text)]
                        try:
                            if content_type == "document":
                                file = await context.bot.get_file(content_id)
                                file_bytes = await file.download_as_bytearray()
                                parts.append(types.Part(inline_data=types.Blob(mime_type=file.mime_type, data=file_bytes)))
                            elif content_type in ["image", "video", "voice"]:
                                file_bytes = await(await context.bot.get_file(content_id)).download_as_bytearray()
                                mime_map = {'image': 'image/jpeg', 'voice': 'audio/ogg', 'video': 'video/mp4'}
                                mime = mime_map.get(content_type)
                                if mime:
                                    parts.append(types.Part(inline_data=types.Blob(mime_type=mime, data=file_bytes)))
                                else:
                                    raise ValueError(f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π content_type: {content_type}")
                            elif content_type == "webpage":
                                prompt_text += f"\n\n–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –µ—â–µ —Ä–∞–∑ —Å—Ç—Ä–∞–Ω–∏—Ü—É: {content_id}"
                                parts[0].text = prompt_text
                                await process_query(update, context, parts, content_type=content_type, content_id=content_id, tools=[types.Tool(url_context=types.UrlContext())])
                                return
                            elif content_type == "youtube":
                                transcript_list = await asyncio.to_thread(YouTubeTranscriptApi.get_transcript, content_id, languages=['ru', 'en'])
                                transcript = " ".join([d['text'] for d in transcript_list])
                                prompt_text += f"\n\n–ò–°–•–û–î–ù–´–ô –¢–†–ê–ù–°–ö–†–ò–ü–¢:\n{transcript}"
                                parts[0].text = prompt_text
                                await process_query(update, context, parts, content_type=content_type, content_id=content_id)
                                return
                            await process_query(update, context, parts, content_type=content_type, content_id=content_id)
                            return
                        except Exception as e:
                            logger.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –∏—Å—Ö–æ–¥–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç –¥–ª—è –æ—Ç–≤–µ—Ç–∞: {e}")
                            await message.reply_text(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –∏—Å—Ö–æ–¥–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç –¥–ª—è –ø–æ–≤—Ç–æ—Ä–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞: {e}")
                            return
                            
    user_prefix = USER_ID_PREFIX_FORMAT.format(user_id=user.id, user_name=html.escape(user.first_name or ''))
    prompt_parts = [types.Part(text=f"(–¢–µ–∫—É—â–∞—è –¥–∞—Ç–∞: {get_current_time_str()})\n{user_prefix}{html.escape(original_text)}")]
    await process_query(update, context, prompt_parts)

async def handle_media(update: Update, context: ContextTypes.DEFAULT_TYPE):
    message, user = update.message, update.effective_user
    logger.info(f"–ü–æ–ª—É—á–µ–Ω–æ –º–µ–¥–∏–∞ –æ—Ç {user.id} –≤ —á–∞—Ç–µ {message.chat_id}")
    if message.photo:
        await handle_photo_with_search(update, context)
        return

    caption = message.caption or "–û–ø–∏—à–∏, —á—Ç–æ –Ω–∞ —ç—Ç–æ–º –º–µ–¥–∏–∞—Ñ–∞–π–ª–µ."
    if message.video:
        file_id, mime_type, content_type = message.video.file_id, message.video.mime_type, "video"
    elif message.voice:
        file_id, mime_type, content_type = message.voice.file_id, message.voice.mime_type, "voice"
        caption = "–†–∞—Å—à–∏—Ñ—Ä—É–π —ç—Ç–æ –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –∏ –æ—Ç–≤–µ—Ç—å –Ω–∞ –Ω–µ–≥–æ."
    else: return

    file_bytes = await (await context.bot.get_file(file_id)).download_as_bytearray()
    media_part = types.Part(inline_data=types.Blob(mime_type=mime_type, data=file_bytes))
    user_prefix = USER_ID_PREFIX_FORMAT.format(user_id=user.id, user_name=html.escape(user.first_name or ''))
    text_part = types.Part(text=f"(–¢–µ–∫—É—â–∞—è –¥–∞—Ç–∞: {get_current_time_str()})\n{user_prefix}{html.escape(caption)}")
    await process_query(update, context, [text_part, media_part], content_type=content_type, content_id=file_id)

async def handle_photo_with_search(update: Update, context: ContextTypes.DEFAULT_TYPE):
    message, user = update.message, update.effective_user
    logger.info(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–æ—Ç–æ –æ—Ç {user.id} –≤ —á–∞—Ç–µ {message.chat_id}")
    client = context.bot_data['gemini_client']
    await context.bot.send_chat_action(chat_id=message.chat_id, action=ChatAction.TYPING)
    photo_file = message.photo[-1]
    file_bytes = await (await context.bot.get_file(photo_file.file_id)).download_as_bytearray()
    media_part = types.Part(inline_data=types.Blob(mime_type='image/jpeg', data=file_bytes))
    extraction_prompt = "–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —ç—Ç–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ. –ï—Å–ª–∏ –Ω–∞ –Ω–µ–º –µ—Å—Ç—å —Ö–æ—Ä–æ—à–æ —á–∏—Ç–∞–µ–º—ã–π —Ç–µ–∫—Å—Ç, –∏–∑–≤–ª–µ–∫–∏ –µ–≥–æ. –ï—Å–ª–∏ —Ç–µ–∫—Å—Ç–∞ –Ω–µ—Ç, –æ–ø–∏—à–∏ –∫–ª—é—á–µ–≤—ã–µ –æ–±—ä–µ–∫—Ç—ã 1-3 —Å–ª–æ–≤–∞–º–∏. –û—Ç–≤–µ—Ç –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –û–ß–ï–ù–¨ –∫–æ—Ä–æ—Ç–∫–∏–º –∏ —Å–æ–¥–µ—Ä–∂–∞—Ç—å —Ç–æ–ª—å–∫–æ —Ç–µ–∫—Å—Ç –∏–ª–∏ —Å–ª–æ–≤–∞, –ø–æ–¥—Ö–æ–¥—è—â–∏–µ –¥–ª—è –≤–µ–±-–ø–æ–∏—Å–∫–∞."
    search_query = None
    try:
        model = client.generative_models(DEFAULT_MODEL)
        response_extract = await model.generate_content_async(contents=[types.Part(text=extraction_prompt), media_part])
        search_query = response_extract.text.strip()
    except Exception as e:
        logger.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–∏ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ —Å —Ñ–æ—Ç–æ: {e}")
    caption = message.caption or "–ü–æ–¥—Ä–æ–±–Ω–æ –æ–ø–∏—à–∏ —ç—Ç–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ."
    user_prefix = USER_ID_PREFIX_FORMAT.format(user_id=user.id, user_name=html.escape(user.first_name or ''))
    final_text_prompt = f"(–¢–µ–∫—É—â–∞—è –¥–∞—Ç–∞: {get_current_time_str()})\n{user_prefix}{html.escape(caption)}"
    if search_query and len(search_query) > 2:
        await message.reply_text(f"üîç –ù–∞—à–µ–ª –Ω–∞ –∫–∞—Ä—Ç–∏–Ω–∫–µ ¬´<i>{html.escape(search_query[:60])}</i>¬ª, –∏—â—É –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é...", parse_mode=ParseMode.HTML)
        final_text_prompt += f"\n\n–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ, –∞ —Ç–∞–∫–∂–µ –∏—Å–ø–æ–ª—å–∑—É–π –ø–æ–∏—Å–∫, —á—Ç–æ–±—ã –¥–æ–ø–æ–ª–Ω–∏—Ç—å –æ—Ç–≤–µ—Ç –ø–æ —Ç–µ–º–µ: '{search_query}'."
    final_prompt_parts = [types.Part(text=final_text_prompt), media_part]
    await process_query(update, context, final_prompt_parts, content_type="image", content_id=photo_file.file_id)

async def handle_document(update: Update, context: ContextTypes.DEFAULT_TYPE):
    doc = update.message.document
    logger.info(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞ '{doc.file_name}' ({doc.mime_type}) –æ—Ç {update.effective_user.id}")
    
    if doc.file_size > 20 * 1024 * 1024:
        await update.message.reply_text("‚ùå –§–∞–π–ª —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π (–ª–∏–º–∏—Ç 20 –ú–ë)."); return

    await update.message.reply_text(f"üìÑ –ß–∏—Ç–∞—é —Ñ–∞–π–ª '{doc.file_name}'...")
    try:
        file_bytes = await (await doc.get_file()).download_as_bytearray()
        file_part = types.Part(inline_data=types.Blob(mime_type=doc.mime_type, data=file_bytes))
        caption = update.message.caption or f"–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —ç—Ç–æ–≥–æ —Ñ–∞–π–ª–∞ ({doc.file_name})."
        user_prefix = USER_ID_PREFIX_FORMAT.format(user_id=update.effective_user.id, user_name=html.escape(update.effective_user.first_name or ''))
        text_part = types.Part(text=f"(–¢–µ–∫—É—â–∞—è –¥–∞—Ç–∞: {get_current_time_str()})\n{user_prefix}{html.escape(caption)}")
        prompt_parts = [text_part, file_part]
        await process_query(update, context, prompt_parts, content_type="document", content_id=doc.file_id)
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞ {doc.file_name}: {e}", exc_info=True)
        await update.message.reply_text(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å —Ñ–∞–π–ª: {e}")

# --- –ù–û–í–´–ô –ú–ï–•–ê–ù–ò–ó–ú –ó–ê–ü–£–°–ö–ê ---
async def worker(application: Application, update_queue: asyncio.Queue):
    logger.info("–í–æ—Ä–∫–µ—Ä –∑–∞–ø—É—â–µ–Ω –∏ –≥–æ—Ç–æ–≤ –∫ —Ä–∞–±–æ—Ç–µ.")
    while True:
        try:
            update_json = await update_queue.get()
            logger.info("–í–æ—Ä–∫–µ—Ä –ø–æ–ª—É—á–∏–ª –Ω–æ–≤–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∏–∑ –æ—á–µ—Ä–µ–¥–∏.")
            update = Update.de_json(json.loads(update_json) if isinstance(update_json, str) else update_json, application.bot)
            await application.process_update(update)
            update_queue.task_done()
        except asyncio.CancelledError:
            logger.info("–í–æ—Ä–∫–µ—Ä –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω.")
            break
        except Exception:
            logger.error("–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –≤ –≤–æ—Ä–∫–µ—Ä–µ:", exc_info=True)

async def run_web_server(update_queue: asyncio.Queue, stop_event: asyncio.Event):
    app = aiohttp.web.Application()
    async def webhook_handler(request: aiohttp.web.Request):
        try:
            logger.info(f"–ü–æ–ª—É—á–µ–Ω –≤—Ö–æ–¥—è—â–∏–π –∑–∞–ø—Ä–æ—Å –Ω–∞ –≤–µ–±—Ö—É–∫ –æ—Ç {request.remote}")
            await update_queue.put(await request.json())
            return aiohttp.web.Response(status=200)
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –≤ –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–µ –≤–µ–±—Ö—É–∫–∞ (–¥–æ –æ—á–µ—Ä–µ–¥–∏): {e}", exc_info=True)
            return aiohttp.web.Response(status=500)
    app.router.add_post(f"/{GEMINI_WEBHOOK_PATH.strip('/')}", webhook_handler)
    app.router.add_get('/', lambda r: aiohttp.web.Response(text="Bot is running"))

    runner = aiohttp.web.AppRunner(app)
    await runner.setup()
    site = aiohttp.web.TCPSite(runner, "0.0.0.0", int(os.getenv("PORT", "10000")))

    try:
        await site.start()
        logger.info(f"–í–µ–±-—Å–µ—Ä–≤–µ—Ä –∑–∞–ø—É—â–µ–Ω –Ω–∞ –ø–æ—Ä—Ç—É {os.getenv('PORT', '10000')}.")
        await stop_event.wait()
    finally:
        await runner.cleanup()
        logger.info("–í–µ–±-—Å–µ—Ä–≤–µ—Ä –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω.")

async def main():
    stop_event = asyncio.Event()
    loop = asyncio.get_running_loop()
    for sig in (signal.SIGINT, signal.SIGTERM): loop.add_signal_handler(sig, stop_event.set)

    update_queue = asyncio.Queue()

    persistence = PostgresPersistence(DATABASE_URL) if DATABASE_URL else None
    builder = Application.builder().token(TELEGRAM_BOT_TOKEN)
    if persistence: builder.persistence(persistence)
    application = builder.build()

    doc_filter = filters.Document.MimeType(
        ['application/pdf', 'text/plain', 'text/markdown', 'text/csv', 'text/html', 'text/xml', 'application/json', 'text/css']
    )

    handlers = [
        CommandHandler("start", start), CommandHandler("clear", clear_history),
        CommandHandler("thinking", thinking_command), CommandHandler("transcribe", transcribe_command),
        CommandHandler("summarize_url", summarize_url_command), CommandHandler("summarize_yt", summarize_yt_command),
        CallbackQueryHandler(select_thinking_callback, pattern="^set_thinking_"),
        MessageHandler(filters.PHOTO, handle_media),
        MessageHandler(filters.VIDEO | filters.VOICE, handle_media),
        MessageHandler(doc_filter, handle_document),
        MessageHandler(filters.TEXT & ~filters.COMMAND, handle_text_and_replies)
    ]
    application.add_handlers(handlers)

    web_task, worker_task = None, None
    try:
        web_task = asyncio.create_task(run_web_server(update_queue, stop_event))

        await application.initialize()
        logger.info("–ü—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ.")

        genai.configure(api_key=GOOGLE_API_KEY)
        application.bot_data['gemini_client'] = genai
        
        application.bot_data['http_client'] = httpx.AsyncClient()
        logger.info("API –∫–ª–∏–µ–Ω—Ç—ã (Gemini, HTTPX) —É—Å–ø–µ—à–Ω–æ —Å–æ–∑–¥–∞–Ω—ã –∏ –¥–æ–±–∞–≤–ª–µ–Ω—ã –≤ bot_data.")

        worker_task = asyncio.create_task(worker(application, update_queue))

        webhook_url = f"{WEBHOOK_HOST.rstrip('/')}/{GEMINI_WEBHOOK_PATH.strip('/')}"
        await application.bot.set_webhook(url=webhook_url, allowed_updates=Update.ALL_TYPES, secret_token=os.getenv('WEBHOOK_SECRET_TOKEN'))
        logger.info(f"–í–µ–±—Ö—É–∫ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω: {webhook_url}")

        commands = [
            BotCommand("start", "–ò–Ω—Ñ–æ –∏ –ø–æ–º–æ—â—å"), BotCommand("clear", "–û—á–∏—Å—Ç–∏—Ç—å –∏—Å—Ç–æ—Ä–∏—é"),
            BotCommand("thinking", "–ù–∞—Å—Ç—Ä–æ–∏—Ç—å —Ä–µ–∂–∏–º —Ä–∞–∑–º—ã—à–ª–µ–Ω–∏–π"), BotCommand("transcribe", "–†–∞—Å—à–∏—Ñ—Ä–æ–≤–∞—Ç—å –∞—É–¥–∏–æ (–æ—Ç–≤–µ—Ç–æ–º)"),
            BotCommand("summarize_yt", "–ö–æ–Ω—Å–ø–µ–∫—Ç –≤–∏–¥–µ–æ YouTube"), BotCommand("summarize_url", "–í—ã–∂–∏–º–∫–∞ –∏–∑ —Å—Ç–∞—Ç—å–∏")
        ]
        await application.bot.set_my_commands(commands)
        logger.info("–ö–æ–º–∞–Ω–¥—ã –±–æ—Ç–∞ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã.")

        await stop_event.wait()

    finally:
        logger.info("--- –û—Å—Ç–∞–Ω–æ–≤–∫–∞ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è ---")
        tasks_to_cancel = [t for t in [web_task, worker_task] if t and not t.done()]
        if tasks_to_cancel:
            for task in tasks_to_cancel:
                task.cancel()
            await asyncio.gather(*tasks_to_cancel, return_exceptions=True)

        if application:
            if http_client := application.bot_data.get('http_client'):
                if not http_client.is_closed: await http_client.aclose()
            await application.shutdown()
            if persistence: persistence.close()
        logger.info("--- –ü—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –ø–æ–ª–Ω–æ—Å—Ç—å—é –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ ---")

if __name__ == '__main__':
    try:
        asyncio.run(main())
    except (KeyboardInterrupt, SystemExit):
        logger.info("–ü—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º.")
