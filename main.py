# –í–µ—Ä—Å–∏—è 25.9 'Pure Context'
# 1. –ö–†–ò–¢–ò–ß–ï–°–ö–û–ï –ò–ó–ú–ï–ù–ï–ù–ò–ï: –ò–∑ –≤—Å–µ—Ö –º–µ–¥–∏–∞-–æ–±—Ä–∞–±–æ—Ç—á–∏–∫–æ–≤ —É–¥–∞–ª–µ–Ω—ã –∂–µ—Å—Ç–∫–æ –∑–∞–¥–∞–Ω–Ω—ã–µ "–ø—Ä–æ–º–ø—Ç—ã-–Ω–∞–¥—Å–º–æ—Ç—Ä—â–∏–∫–∏". –¢–µ–ø–µ—Ä—å –º–æ–¥–µ–ª—å –ø–æ–ª—É—á–∞–µ—Ç –ª–∏–±–æ —Ç–µ–∫—Å—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è (caption), –ª–∏–±–æ –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –Ω–µ–π—Ç—Ä–∞–ª—å–Ω—ã–π –ø—Ä–æ–º–ø—Ç.
# 2. –†–ï–ó–£–õ–¨–¢–ê–¢: –ü–æ–≤–µ–¥–µ–Ω–∏–µ –±–æ—Ç–∞ —Ç–µ–ø–µ—Ä—å –ø–æ–ª–Ω–æ—Å—Ç—å—é –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç—Å—è –ø—Ä–∞–≤–∏–ª–∞–º–∏ –∏–∑ `system_prompt.md`, –∞ –Ω–µ "–∫–æ—Å—Ç—ã–ª—è–º–∏" –≤ –∫–æ–¥–µ. –≠—Ç–æ –æ–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç –ø—Ä–µ–¥—Å–∫–∞–∑—É–µ–º–æ—Å—Ç—å –∏ –≥–∏–±–∫–æ—Å—Ç—å.
# 3. –£–õ–£–ß–®–ï–ù–û: –ú–µ—Ö–∞–Ω–∏–∑–º "–ª–∏–ø–∫–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞" –∏ –≤—Å–µ –æ—Å—Ç–∞–ª—å–Ω—ã–µ —Ä–∞–±–æ—á–∏–µ —Ñ—É–Ω–∫—Ü–∏–∏ –∞–¥–∞–ø—Ç–∏—Ä–æ–≤–∞–Ω—ã –ø–æ–¥ –Ω–æ–≤—É—é –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É.

import logging
import os
import asyncio
import signal
import re
import pickle
from collections import defaultdict, OrderedDict
import psycopg2
from psycopg2 import pool
import io
import time
import datetime
import pytz

import httpx
import aiohttp
import aiohttp.web
from telegram import Update, Message, BotCommand, InlineKeyboardButton, InlineKeyboardMarkup
from telegram.constants import ChatAction, ParseMode
from telegram.ext import Application, CommandHandler, MessageHandler, ContextTypes, filters, BasePersistence, CallbackQueryHandler
from telegram.error import BadRequest

from google import genai
from google.genai import types
from duckduckgo_search import DDGS

# --- –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø ---
log_level = os.getenv("LOG_LEVEL", "INFO").upper()
logging.basicConfig(format='%(asctime)s - %(name)s - %(levelname)s - %(message)s', level=log_level)
logger = logging.getLogger(__name__)

TELEGRAM_BOT_TOKEN = os.getenv('TELEGRAM_BOT_TOKEN')
GOOGLE_API_KEY = os.getenv('GOOGLE_API_KEY')
DATABASE_URL = os.getenv('DATABASE_URL')
WEBHOOK_HOST = os.getenv('WEBHOOK_HOST')
GEMINI_WEBHOOK_PATH = os.getenv('GEMINI_WEBHOOK_PATH')
 
if not all([TELEGRAM_BOT_TOKEN, GOOGLE_API_KEY, WEBHOOK_HOST, GEMINI_WEBHOOK_PATH]):
    logger.critical("–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: –Ω–µ –∑–∞–¥–∞–Ω—ã –≤—Å–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è!")
    exit(1)

# --- –ö–û–ù–°–¢–ê–ù–¢–´ –ò –ù–ê–°–¢–†–û–ô–ö–ò ---
MODEL_NAME = 'gemini-2.5-flash'
YOUTUBE_REGEX = r'(?:https?:\/\/)?(?:www\.|m\.)?(?:youtube\.com\/(?:watch\?v=|shorts\/)|youtu\.be\/)([a-zA-Z0-9_-]{11})'
URL_REGEX = r'https?:\/\/[^\s/$.?#].[^\s]*'
MAX_CONTEXT_CHARS = 120000 
MAX_HISTORY_RESPONSE_LEN = 2000
MAX_HISTORY_ITEMS = 50
MAX_MEDIA_CONTEXTS = 10 

# --- –ò–ù–°–¢–†–£–ú–ï–ù–¢–´ –ò –ü–†–û–ú–ü–¢–´ ---
def get_current_time_str(timezone: str = "Europe/Moscow") -> str:
    return datetime.datetime.now(pytz.timezone(timezone)).strftime('%Y-%m-%d %H:%M:%S %Z')

TEXT_TOOLS = [types.Tool(google_search=types.GoogleSearch()), types.Tool(code_execution=types.ToolCodeExecution())]
MEDIA_TOOLS = [types.Tool(google_search=types.GoogleSearch())]
FUNCTION_CALLING_TOOLS = [types.Tool(function_declarations=[types.FunctionDeclaration(
    name='get_current_time_str', description="Gets the current date and time.",
    parameters=types.Schema(type=types.Type.OBJECT, properties={'timezone': types.Schema(type=types.Type.STRING)})
)])]
SAFETY_SETTINGS = [
    types.SafetySetting(category=c, threshold=types.HarmBlockThreshold.BLOCK_NONE)
    for c in (types.HarmCategory.HARM_CATEGORY_HARASSMENT, types.HarmCategory.HARM_CATEGORY_HATE_SPEECH,
              types.HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT, types.HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT)
]

try:
    with open('system_prompt.md', 'r', encoding='utf-8') as f: SYSTEM_INSTRUCTION = f.read()
    logger.info("–°–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω –∏–∑ —Ñ–∞–π–ª–∞.")
except FileNotFoundError:
    logger.error("–§–∞–π–ª system_prompt.md –Ω–µ –Ω–∞–π–¥–µ–Ω! –ë—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∞ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é.")
    SYSTEM_INSTRUCTION = "You are a helpful and friendly assistant named Zhenya."

# --- –ö–õ–ê–°–° PERSISTENCE ---
class PostgresPersistence(BasePersistence):
    def __init__(self, database_url: str):
        super().__init__()
        self.db_pool = None
        self.dsn = database_url
        try: self._connect(); self._initialize_db()
        except psycopg2.Error as e: logger.critical(f"PostgresPersistence: –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ –ë–î: {e}"); raise
    def _connect(self):
        if self.db_pool:
            try: self.db_pool.closeall()
            except Exception as e: logger.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–∫—Ä—ã—Ç–∏–∏ —Å—Ç–∞—Ä–æ–≥–æ –ø—É–ª–∞: {e}")
        dsn = self.dsn
        keepalive_options = "keepalives=1&keepalives_idle=60&keepalives_interval=10&keepalives_count=5"
        if "?" in dsn:
             if "keepalives" not in dsn: dsn = f"{dsn}&{keepalive_options}"
        else: dsn = f"{dsn}?{keepalive_options}"
        self.db_pool = psycopg2.pool.SimpleConnectionPool(1, 10, dsn=dsn)
    
    def _execute(self, query: str, params: tuple = None, fetch: str = None, retries=3):
        last_exception = None
        for attempt in range(retries):
            conn = None
            try:
                conn = self.db_pool.getconn()
                with conn.cursor() as cur:
                    cur.execute(query, params)
                    if fetch == "one": return cur.fetchone()
                    if fetch == "all": return cur.fetchall()
                    conn.commit()
                return True
            except (psycopg2.OperationalError, psycopg2.InterfaceError) as e:
                logger.warning(f"Postgres: –û—à–∏–±–∫–∞ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è (–ø–æ–ø—ã—Ç–∫–∞ {attempt + 1}/{retries}): {e}")
                last_exception = e
                if conn:
                    self.db_pool.putconn(conn, close=True)
                    conn = None
                if attempt < retries - 1:
                    time.sleep(1 + attempt)
                continue
            finally:
                if conn: self.db_pool.putconn(conn)
        
        logger.error(f"Postgres: –ù–µ —É–¥–∞–ª–æ—Å—å –≤—ã–ø–æ–ª–Ω–∏—Ç—å –∑–∞–ø—Ä–æ—Å –ø–æ—Å–ª–µ {retries} –ø–æ–ø—ã—Ç–æ–∫. –ü–æ—Å–ª–µ–¥–Ω—è—è –æ—à–∏–±–∫–∞: {last_exception}")
        if last_exception: raise last_exception

    def _initialize_db(self): self._execute("CREATE TABLE IF NOT EXISTS persistence_data (key TEXT PRIMARY KEY, data BYTEA NOT NULL);")
    def _get_pickled(self, key: str) -> object | None:
        res = self._execute("SELECT data FROM persistence_data WHERE key = %s;", (key,), fetch="one")
        return pickle.loads(res[0]) if res and res[0] else None
    def _set_pickled(self, key: str, data: object) -> None: self._execute("INSERT INTO persistence_data (key, data) VALUES (%s, %s) ON CONFLICT (key) DO UPDATE SET data = %s;", (key, pickle.dumps(data), pickle.dumps(data)))
    async def get_bot_data(self) -> dict: return {}
    async def update_bot_data(self, data: dict) -> None: pass
    async def get_chat_data(self) -> defaultdict[int, dict]:
        all_data = await asyncio.to_thread(self._execute, "SELECT key, data FROM persistence_data WHERE key LIKE 'chat_data_%';", fetch="all")
        chat_data = defaultdict(dict)
        if all_data:
            for k, d in all_data:
                try: chat_data[int(k.split('_')[-1])] = pickle.loads(d)
                except (ValueError, IndexError, pickle.UnpicklingError): logger.warning(f"–û–±–Ω–∞—Ä—É–∂–µ–Ω –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π –∫–ª—é—á –∏–ª–∏ –¥–∞–Ω–Ω—ã–µ —á–∞—Ç–∞ –≤ –ë–î: '{k}'. –ó–∞–ø–∏—Å—å –ø—Ä–æ–ø—É—â–µ–Ω–∞.")
        return chat_data
    async def update_chat_data(self, chat_id: int, data: dict) -> None: await asyncio.to_thread(self._set_pickled, f"chat_data_{chat_id}", data)
    async def drop_chat_data(self, chat_id: int) -> None: await asyncio.to_thread(self._execute, "DELETE FROM persistence_data WHERE key = %s;", (f"chat_data_{chat_id}",))
    async def refresh_chat_data(self, chat_id: int, chat_data: dict) -> None:
        try:
            data = await asyncio.to_thread(self._get_pickled, f"chat_data_{chat_id}") or {}
            chat_data.update(data)
        except psycopg2.Error as e:
            logger.critical(f"–ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê –ë–î: –ù–µ —É–¥–∞–ª–æ—Å—å –æ–±–Ω–æ–≤–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –¥–ª—è —á–∞—Ç–∞ {chat_id}. –û—à–∏–±–∫–∞: {e}")
    async def get_user_data(self) -> defaultdict[int, dict]: return defaultdict(dict)
    async def update_user_data(self, user_id: int, data: dict) -> None: pass
    async def drop_user_data(self, user_id: int) -> None: pass
    async def get_callback_data(self) -> dict | None: return None
    async def update_callback_data(self, data: dict) -> None: pass
    async def get_conversations(self, name: str) -> dict: return {}
    async def update_conversation(self, name: str, key: tuple, new_state: object | None) -> None: pass
    async def refresh_bot_data(self, bot_data: dict) -> None: pass
    async def refresh_user_data(self, user_id: int, user_data: dict) -> None: pass
    async def flush(self) -> None: pass
    def close(self):
        if self.db_pool: self.db_pool.closeall()

# --- –í–°–ü–û–ú–û–ì–ê–¢–ï–õ–¨–ù–´–ï –§–£–ù–ö–¶–ò–ò ---
def get_user_setting(context: ContextTypes.DEFAULT_TYPE, key: str, default_value): return context.chat_data.get(key, default_value)
def set_user_setting(context: ContextTypes.DEFAULT_TYPE, key: str, value): context.chat_data[key] = value

def html_safe_chunker(text_to_chunk: str, chunk_size: int = 4096) -> list[str]:
    chunks, tag_stack, remaining_text = [], [], text_to_chunk
    tag_regex = re.compile(r'<(/?)(b|i|u|s|code|pre|a|tg-spoiler|br)>', re.IGNORECASE)
    while len(remaining_text) > chunk_size:
        split_pos = remaining_text.rfind('\n', 0, chunk_size)
        if split_pos == -1: split_pos = chunk_size
        current_chunk = remaining_text[:split_pos]
        temp_stack = list(tag_stack)
        for match in tag_regex.finditer(current_chunk):
            tag_name, is_closing = match.group(2).lower(), bool(match.group(1))
            if tag_name == 'br': continue
            if not is_closing: temp_stack.append(tag_name)
            elif temp_stack and temp_stack[-1] == tag_name: temp_stack.pop()
        closing_tags = ''.join(f'</{tag}>' for tag in reversed(temp_stack))
        chunks.append(current_chunk + closing_tags)
        tag_stack = temp_stack
        opening_tags = ''.join(f'<{tag}>' for tag in tag_stack)
        remaining_text = opening_tags + remaining_text[split_pos:].lstrip()
    chunks.append(remaining_text)
    return chunks

async def send_reply(target_message: Message, text: str) -> Message | None:
    sanitized_text = re.sub(r'<br\s*/?>', '\n', text)
    chunks = html_safe_chunker(sanitized_text)
    sent_message = None
    try:
        for i, chunk in enumerate(chunks):
            if i == 0: sent_message = await target_message.reply_html(chunk)
            else: sent_message = await target_message.get_bot().send_message(chat_id=target_message.chat_id, text=chunk, parse_mode=ParseMode.HTML)
            await asyncio.sleep(0.1)
        return sent_message
    except BadRequest as e:
        if "Can't parse entities" in str(e) or "unsupported start tag" in str(e):
            logger.warning(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ HTML: {e}. –û—Ç–ø—Ä–∞–≤–ª—è—é –∫–∞–∫ –æ–±—ã—á–Ω—ã–π —Ç–µ–∫—Å—Ç.")
            plain_text = re.sub(r'<[^>]*>', '', sanitized_text)
            chunks = html_safe_chunker(plain_text)
            for i, chunk in enumerate(chunks):
                if i == 0: sent_message = await target_message.reply_text(chunk)
                else: sent_message = await target_message.get_bot().send_message(chat_id=target_message.chat_id, text=chunk)
            return sent_message
    except Exception as e: logger.error(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ –æ—Ç–≤–µ—Ç–∞: {e}", exc_info=True)
    return None

def part_to_dict(part: types.Part) -> dict:
    if part.text: return {'type': 'text', 'content': part.text}
    if part.file_data: return {'type': 'file', 'uri': part.file_data.file_uri, 'mime': part.file_data.mime_type}
    return {}

def dict_to_part(part_dict: dict) -> types.Part | None:
    if not isinstance(part_dict, dict): return None
    if part_dict.get('type') == 'text': return types.Part(text=part_dict.get('content', ''))
    if part_dict.get('type') == 'file': return types.Part(file_data=types.FileData(file_uri=part_dict['uri'], mime_type=part_dict['mime']))
    return None

async def add_to_history(context: ContextTypes.DEFAULT_TYPE, role: str, parts: list[types.Part], **kwargs):
    chat_history = context.chat_data.setdefault("history", [])
    
    processed_parts = []
    if role == 'model':
        text_part = next((p.text for p in parts if p.text), None)
        if text_part:
            if kwargs.get('is_media_response'):
                processed_parts.append(types.Part(text="[–ë—ã–ª –¥–∞–Ω –æ—Ç–≤–µ—Ç –Ω–∞ –º–µ–¥–∏–∞-–∑–∞–ø—Ä–æ—Å]"))
            elif len(text_part) > MAX_HISTORY_RESPONSE_LEN:
                text_to_save = (text_part[:MAX_HISTORY_RESPONSE_LEN] + "...")
                logger.info(f"–û—Ç–≤–µ—Ç –º–æ–¥–µ–ª–∏ –¥–ª—è —á–∞—Ç–∞ {context.chat_data.get('id')} –±—ã–ª –æ–±—Ä–µ–∑–∞–Ω –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤ –∏—Å—Ç–æ—Ä–∏—é.")
                processed_parts.append(types.Part(text=text_to_save))
            else:
                processed_parts.append(types.Part(text=text_part))
    elif role == 'user':
        text_part = next((p.text for p in parts if p.text), None)
        if text_part:
            processed_parts.append(types.Part(text=text_part))

    serializable_parts = [part_to_dict(p) for p in processed_parts if p]
    if not serializable_parts: return

    entry = {"role": role, "parts": serializable_parts, **kwargs}
    chat_history.append(entry)
    if len(chat_history) > MAX_HISTORY_ITEMS:
        context.chat_data["history"] = chat_history[-MAX_HISTORY_ITEMS:]
    await context.application.persistence.update_chat_data(context.chat_data.get('id'), context.chat_data)

def build_history_for_request(chat_history: list) -> list[types.Content]:
    valid_history, current_chars = [], 0
    for entry in reversed(chat_history):
        if entry.get("role") in ("user", "model") and isinstance(entry.get("parts"), list):
            api_parts = [p for p in (dict_to_part(part_dict) for part_dict in entry["parts"]) if p is not None]
            if not api_parts: continue
            entry_text_len = sum(len(p.text) for p in api_parts if p.text)
            if current_chars + entry_text_len > MAX_CONTEXT_CHARS:
                logger.info(f"–î–æ—Å—Ç–∏–≥–Ω—É—Ç –ª–∏–º–∏—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ ({MAX_CONTEXT_CHARS} —Å–∏–º–≤). –ò—Å—Ç–æ—Ä–∏—è –æ–±—Ä–µ–∑–∞–Ω–∞ –¥–æ {len(valid_history)} —Å–æ–æ–±—â–µ–Ω–∏–π.")
                break
            clean_content = types.Content(role=entry["role"], parts=api_parts)
            valid_history.append(clean_content)
            current_chars += entry_text_len
    valid_history.reverse()
    return valid_history

def find_media_context_in_history(context: ContextTypes.DEFAULT_TYPE, reply_to_id: int) -> dict | None:
    history = context.chat_data.get("history", [])
    media_contexts = context.chat_data.get("media_contexts", {})
    current_reply_id = reply_to_id
    for _ in range(len(history)): 
        bot_message = next((msg for msg in reversed(history) if msg.get("role") == "model" and msg.get("bot_message_id") == current_reply_id), None)
        if bot_message and 'original_message_id' in bot_message:
            user_msg_id = bot_message['original_message_id']
            if user_msg_id in media_contexts:
                return media_contexts[user_msg_id]
            current_reply_id = user_msg_id
        else:
            if current_reply_id in media_contexts:
                return media_contexts[current_reply_id]
            break
    return None

async def upload_and_wait_for_file(client: genai.Client, file_bytes: bytes, mime_type: str, file_name: str) -> types.Part:
    logger.info(f"–ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–∞ '{file_name}' ({len(file_bytes) / 1024:.2f} KB) —á–µ—Ä–µ–∑ File API...")
    uploaded_file_response = await client.aio.files.upload(
        file=io.BytesIO(file_bytes), config=types.UploadFileConfig(mime_type=mime_type, display_name=file_name)
    )
    logger.info(f"–§–∞–π–ª '{file_name}' –∑–∞–≥—Ä—É–∂–µ–Ω. –ò–º—è: {uploaded_file_response.name}. –û–∂–∏–¥–∞–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞ ACTIVE...")
    for _ in range(15):
        file_state_response = await client.aio.files.get(name=uploaded_file_response.name)
        state = file_state_response.state.name
        if state == 'ACTIVE':
            logger.info(f"–§–∞–π–ª '{file_name}' –∞–∫—Ç–∏–≤–µ–Ω.")
            return types.Part(file_data=types.FileData(file_uri=uploaded_file_response.uri, mime_type=mime_type))
        if state == 'FAILED':
            raise IOError(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ñ–∞–π–ª–∞ '{file_name}' –Ω–∞ —Å–µ—Ä–≤–µ—Ä–µ Google.")
        await asyncio.sleep(2)
    raise asyncio.TimeoutError(f"–§–∞–π–ª '{file_name}' –Ω–µ —Å—Ç–∞–ª –∞–∫—Ç–∏–≤–Ω—ã–º –∑–∞ 30 —Å–µ–∫—É–Ω–¥.")

async def perform_proactive_search(query: str) -> str | None:
    try:
        logger.info(f"–í—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è –ø—Ä–æ–∞–∫—Ç–∏–≤–Ω—ã–π –ø–æ–∏—Å–∫ –ø–æ –∑–∞–ø—Ä–æ—Å—É: '{query}'")
        results = await asyncio.to_thread(DDGS().text, keywords=query, region='ru-ru', max_results=5)
        if results:
            snippets = "\n".join(f"- {r['body']}" for r in results)
            logger.info("–ü—Ä–æ–∞–∫—Ç–∏–≤–Ω—ã–π –ø–æ–∏—Å–∫: –£—Å–ø–µ—à–Ω–æ –ø–æ–ª—É—á–µ–Ω—ã —Å–Ω–∏–ø–ø–µ—Ç—ã –∏–∑ DuckDuckGo.")
            return snippets
    except Exception as e:
        logger.warning(f"–ü—Ä–æ–∞–∫—Ç–∏–≤–Ω—ã–π DDG –ø–æ–∏—Å–∫ –Ω–µ —É–¥–∞–ª—Å—è: {e}")
    return None

async def generate_response(client: genai.Client, request_contents: list, context: ContextTypes.DEFAULT_TYPE, tools: list) -> str:
    chat_id = context.chat_data.get('id', 'Unknown')
    thinking_mode = get_user_setting(context, 'thinking_mode', 'auto')
    config = types.GenerateContentConfig(
        safety_settings=SAFETY_SETTINGS, 
        tools=tools,
        thinking_config=types.ThinkingConfig(thinking_budget=-1 if thinking_mode == 'auto' else 24576),
        system_instruction=types.Content(parts=[types.Part(text=SYSTEM_INSTRUCTION)])
    )
    try:
        response = await client.aio.models.generate_content(model=MODEL_NAME, contents=request_contents, config=config)
        logger.info(f"ChatID: {chat_id} | –û—Ç–≤–µ—Ç –ø–æ–ª—É—á–µ–Ω.")
        return response.text
    except Exception as e:
        logger.error(f"ChatID: {chat_id} | –û—à–∏–±–∫–∞: {e}", exc_info=True)
        return f"‚ùå –û—à–∏–±–∫–∞ –º–æ–¥–µ–ª–∏: {str(e)[:250]}"

async def process_request(update: Update, context: ContextTypes.DEFAULT_TYPE, content_parts: list, is_media_request: bool = False):
    message, client = update.message, context.bot_data['gemini_client']
    user = message.from_user
    await context.bot.send_chat_action(chat_id=message.chat_id, action=ChatAction.TYPING)
    
    history = build_history_for_request(context.chat_data.get("history", []))
    tools = MEDIA_TOOLS if is_media_request else TEXT_TOOLS
    
    request_specific_parts = list(content_parts)
    text_part_index = next((i for i, part in enumerate(request_specific_parts) if part.text), -1)
    if text_part_index != -1:
        original_text = request_specific_parts[text_part_index].text
        
        if get_user_setting(context, 'proactive_search', True) and not is_media_request:
            search_results = await perform_proactive_search(original_text)
            search_context = f"\n\n--- –ö–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –≤–µ–±–∞ –¥–ª—è —Å–ø—Ä–∞–≤–∫–∏ ---\n{search_results}\n--------------------------\n" if search_results else ""
        else:
            search_context = ""

        user_prefix = f"[{user.id}; Name: {user.first_name}]: "
        date_prefix = f"(System Note: Today is {get_current_time_str()}. Verify facts using Google Search.)\n"
        request_specific_parts[text_part_index].text = f"{date_prefix}{search_context}{user_prefix}{original_text}"

    request_contents = history + [types.Content(parts=request_specific_parts, role="user")]

    try:
        reply_text = await generate_response(client, request_contents, context, tools)
        sent_message = await send_reply(message, reply_text)
        
        await add_to_history(context, role="user", parts=content_parts, original_message_id=message.message_id)
        if sent_message:
            await add_to_history(context, role="model", parts=[types.Part(text=reply_text)], original_message_id=message.message_id, bot_message_id=sent_message.message_id, is_media_response=is_media_request)
        
        if is_media_request:
            media_part = next((p for p in content_parts if p.file_data), None)
            if media_part:
                media_contexts = context.chat_data.setdefault('media_contexts', OrderedDict())
                media_contexts[message.message_id] = part_to_dict(media_part)
                if len(media_contexts) > MAX_MEDIA_CONTEXTS:
                    media_contexts.popitem(last=False)
                context.chat_data['last_media_context'] = media_contexts[message.message_id]
                logger.info(f"–°–æ—Ö—Ä–∞–Ω–µ–Ω/–æ–±–Ω–æ–≤–ª–µ–Ω –º–µ–¥–∏–∞-–∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è msg_id {message.message_id}")
        elif not message.reply_to_message:
             if 'last_media_context' in context.chat_data:
                del context.chat_data['last_media_context']
                logger.info(f"–û—á–∏—â–µ–Ω '–ª–∏–ø–∫–∏–π' –º–µ–¥–∏–∞-–∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è —á–∞—Ç–∞ {message.chat_id} (–Ω–æ–≤–∞—è —Ç–µ–º–∞).")

    except (IOError, asyncio.TimeoutError) as e:
        logger.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ñ–∞–π–ª–∞: {e}", exc_info=False)
        await message.reply_text(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ñ–∞–π–ª–∞: {e}")
    except Exception as e:
        logger.error(f"–ù–µ–ø—Ä–µ–¥–≤–∏–¥–µ–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ –≤ process_request: {e}", exc_info=True)
        await message.reply_text("‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –≤–Ω—É—Ç—Ä–µ–Ω–Ω—è—è –æ—à–∏–±–∫–∞. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑.")

# --- –û–ë–†–ê–ë–û–¢–ß–ò–ö–ò –ö–û–ú–ê–ù–î ---
async def start_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    context.chat_data.setdefault('thinking_mode', 'auto')
    context.chat_data.setdefault('proactive_search', True)
    start_text = """–Ø - –ñ–µ–Ω—è, –ª—É—á—à–∏–π –ò–ò-—á–∞—Ç-–±–æ—Ç –Ω–∞ Google Gemini 2.5 Flash —Å –∞–≤—Ç–æ—Ä—Å–∫–∏–º–∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏.

üåê –ò—Å–ø–æ–ª—å–∑—É—é –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω—ã–π –ø–æ–∏—Å–∫ Google –≤ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–µ.
üß† –û–±–ª–∞–¥–∞—é –≤—Å–µ–≤–æ–∑–º–æ–∂–Ω—ã–º–∏ –∑–Ω–∞–Ω–∏—è–º–∏ –≤ –ª—é–±—ã—Ö —Å—Ñ–µ—Ä–∞—Ö.
üí¨ –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–≤ –¥–∞–Ω–Ω—ã–µ –∏ –≤–∞—à –∫–æ–Ω—Ç–µ–∫—Å—Ç, –æ—Ç–≤–µ—á—É —Ç–æ—á–Ω–æ, –Ω–æ –≤ –ø–æ–∑–∏—Ç–∏–≤–Ω–æ–º —Å—Ç–∏–ª–µ —Å —é–º–æ—Ä–æ–º.

–ê–Ω–∞–ª–∏–∑, –æ–ø–∏—Å–∞–Ω–∏–µ, —Ä–∞—Å—à–∏—Ñ—Ä–æ–≤–∫–∞ –≤ —Ç–µ–∫—Å—Ç, –ø–µ—Ä–µ—Å–∫–∞–∑, –æ—Ç–≤–µ—Ç—ã –∏ –ø–æ–∏—Å–∫ –ø–æ —Å–æ–¥–µ—Ä–∂–∏–º–æ–º—É:
üé§ –ì–æ–ª–æ—Å–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π –∏ –∞—É–¥–∏–æ—Ñ–∞–π–ª–æ–≤;
üì∏üñº –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π, YouTube-–≤–∏–¥–µ–æ –∏ –≤–∏–¥–µ–æ—Ñ–∞–π–ª–æ–≤ (–¥–æ 50 –º–±);
üîó –í–µ–±-—Å—Ç—Ä–∞–Ω–∏—Ü –∏ —Ñ–∞–π–ª–æ–≤ PDF, TXT, JSON.

–ü–æ–ª—å–∑—É–π—Ç–µ—Å—å —Ç—É—Ç –∏ –¥–æ–±–∞–≤–ª—è–π—Ç–µ –≤ —Å–≤–æ–∏ –≥—Ä—É–ø–ø—ã!

(!) –ò—Å–ø–æ–ª—å–∑—É—è –±–æ—Ç, –í—ã –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å–æ–≥–ª–∞—à–∞–µ—Ç–µ—Å—å –Ω–∞ –ø–µ—Ä–µ–¥–∞—á—É —Å–æ–æ–±—â–µ–Ω–∏–π –∏ —Ñ–∞–π–ª–æ–≤ –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –æ—Ç–≤–µ—Ç–æ–≤ —á–µ—Ä–µ–∑ Google Gemini API."""
    await update.message.reply_html(start_text)

async def config_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    mode = get_user_setting(context, 'thinking_mode', 'auto')
    search = get_user_setting(context, 'proactive_search', True)
    keyboard = [
        [InlineKeyboardButton(f"–ú—ã—à–ª–µ–Ω–∏–µ: {'‚úÖ ' if mode == 'auto' else ''}–ê–≤—Ç–æ", callback_data="set_thinking_auto"),
         InlineKeyboardButton(f"–ú—ã—à–ª–µ–Ω–∏–µ: {'‚úÖ ' if mode == 'max' else ''}–ú–∞–∫—Å–∏–º—É–º", callback_data="set_thinking_max")],
        [InlineKeyboardButton(f"–ü—Ä–æ–∞–∫—Ç–∏–≤–Ω—ã–π –ø–æ–∏—Å–∫: {'‚úÖ –í–∫–ª' if search else '‚ùå –í—ã–∫–ª'}", callback_data="toggle_proactive_search")]
    ]
    await update.message.reply_text("‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏:", reply_markup=InlineKeyboardMarkup(keyboard))

async def config_callback(update: Update, context: ContextTypes.DEFAULT_TYPE):
    query, data = update.callback_query, update.callback_query.data
    await query.answer()
    
    current_mode = get_user_setting(context, 'thinking_mode', 'auto')
    current_search = get_user_setting(context, 'proactive_search', True)

    if data.startswith("set_thinking_"):
        set_user_setting(context, 'thinking_mode', data.replace("set_thinking_", ""))
    elif data == "toggle_proactive_search":
        set_user_setting(context, 'proactive_search', not get_user_setting(context, 'proactive_search', True))
        
    new_mode = get_user_setting(context, 'thinking_mode', 'auto')
    new_search = get_user_setting(context, 'proactive_search', True)

    if current_mode == new_mode and current_search == new_search: return

    keyboard = [
        [InlineKeyboardButton(f"–ú—ã—à–ª–µ–Ω–∏–µ: {'‚úÖ ' if new_mode == 'auto' else ''}–ê–≤—Ç–æ", callback_data="set_thinking_auto"),
         InlineKeyboardButton(f"–ú—ã—à–ª–µ–Ω–∏–µ: {'‚úÖ ' if new_mode == 'max' else ''}–ú–∞–∫—Å–∏–º—É–º", callback_data="set_thinking_max")],
        [InlineKeyboardButton(f"–ü—Ä–æ–∞–∫—Ç–∏–≤–Ω—ã–π –ø–æ–∏—Å–∫: {'‚úÖ –í–∫–ª' if new_search else '‚ùå –í—ã–∫–ª'}", callback_data="toggle_proactive_search")]
    ]
    try:
        await query.edit_message_reply_markup(reply_markup=InlineKeyboardMarkup(keyboard))
    except BadRequest as e:
        if "Message is not modified" in str(e):
            logger.info("–°–æ–æ–±—â–µ–Ω–∏–µ —Å –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏ –Ω–µ –∏–∑–º–µ–Ω–∏–ª–æ—Å—å, –ø—Ä–æ–ø—É—Å–∫ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è.")
        else: raise e

async def clear_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    context.chat_data.clear()
    await context.application.persistence.drop_chat_data(update.effective_chat.id)
    await update.message.reply_text("–ò—Å—Ç–æ—Ä–∏—è —á–∞—Ç–∞ –∏ —Å–≤—è–∑–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –æ—á–∏—â–µ–Ω—ã.")

async def newtopic_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    context.chat_data.pop('last_media_context', None)
    context.chat_data.pop('media_contexts', None)
    await update.message.reply_text("–ö–æ–Ω—Ç–µ–∫—Å—Ç –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö —Ñ–∞–π–ª–æ–≤ –æ—á–∏—â–µ–Ω. –ù–∞—á–∏–Ω–∞–µ–º –Ω–æ–≤—É—é —Ç–µ–º—É.")

async def utility_media_command(update: Update, context: ContextTypes.DEFAULT_TYPE, prompt: str):
    if not update.message.reply_to_message:
        await update.message.reply_text("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ —ç—Ç—É –∫–æ–º–∞–Ω–¥—É –≤ –æ—Ç–≤–µ—Ç –Ω–∞ —Å–æ–æ–±—â–µ–Ω–∏–µ —Å –º–µ–¥–∏–∞—Ñ–∞–π–ª–æ–º –∏–ª–∏ —Å—Å—ã–ª–∫–æ–π.")
        return

    replied_message = update.message.reply_to_message
    media_obj = replied_message.audio or replied_message.voice or replied_message.video or replied_message.photo or replied_message.document
    
    media_part = None
    client = context.bot_data['gemini_client']
    
    try:
        if media_obj:
            media_file = await media_obj.get_file()
            media_bytes = await media_file.download_as_bytearray()
            media_part = await upload_and_wait_for_file(client, media_bytes, media_obj.mime_type, getattr(media_obj, 'file_name', 'media.bin'))
        elif replied_message.text:
            yt_match = re.search(YOUTUBE_REGEX, replied_message.text)
            if yt_match:
                youtube_url = f"https://www.youtube.com/watch?v={yt_match.group(1)}"
                media_part = types.Part(file_data=types.FileData(mime_type="video/youtube", file_uri=youtube_url))
            else:
                await update.message.reply_text("–í —Ü–∏—Ç–∏—Ä—É–µ–º–æ–º —Å–æ–æ–±—â–µ–Ω–∏–∏ –Ω–µ—Ç –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º–æ–≥–æ –º–µ–¥–∏–∞—Ñ–∞–π–ª–∞ –∏–ª–∏ YouTube-—Å—Å—ã–ª–∫–∏.")
                return
        else:
            await update.message.reply_text("–ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –º–µ–¥–∏–∞—Ñ–∞–π–ª –≤ —Ü–∏—Ç–∏—Ä—É–µ–º–æ–º —Å–æ–æ–±—â–µ–Ω–∏–∏.")
            return

        await update.message.reply_text("–ê–Ω–∞–ª–∏–∑–∏—Ä—É—é...", reply_to_message_id=update.message.message_id)
        
        content_parts = [media_part, types.Part(text=prompt)]
        result_text = await generate_response(client, [types.Content(parts=content_parts, role="user")], context, tools=MEDIA_TOOLS)
        await update.message.reply_text(result_text, parse_mode=ParseMode.HTML)

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –≤ —É—Ç–∏–ª–∏—Ç–∞—Ä–Ω–æ–π –∫–æ–º–∞–Ω–¥–µ: {e}", exc_info=True)
        await update.message.reply_text(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –≤—ã–ø–æ–ª–Ω–∏—Ç—å –∫–æ–º–∞–Ω–¥—É: {e}")

async def transcript_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await utility_media_command(update, context, "Transcribe this audio/video file. Return only the transcribed text, without any comments or introductory phrases.")

async def summarize_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await utility_media_command(update, context, "Summarize this material in a few paragraphs. Provide a concise but comprehensive overview.")
    
async def keypoints_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await utility_media_command(update, context, "Extract the key points or main theses from this material. Present them as a structured bulleted list.")

# --- –û–ë–†–ê–ë–û–¢–ß–ò–ö–ò –°–û–û–ë–©–ï–ù–ò–ô ---
async def handle_media_request(update: Update, context: ContextTypes.DEFAULT_TYPE, file_part: types.Part, user_text: str):
    context.chat_data.pop('last_media_context', None)
    content_parts = [file_part, types.Part(text=user_text)]
    await process_request(update, context, content_parts, is_media_request=True)

async def handle_photo(update: Update, context: ContextTypes.DEFAULT_TYPE):
    message, client = update.message, context.bot_data['gemini_client']
    photo_file = await message.photo[-1].get_file()
    photo_bytes = await photo_file.download_as_bytearray()
    file_part = await upload_and_wait_for_file(client, photo_bytes, 'image/jpeg', photo_file.file_unique_id + ".jpg")
    await handle_media_request(update, context, file_part, message.caption or "–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —ç—Ç–æ—Ç —Ñ–∞–π–ª.")

async def handle_document(update: Update, context: ContextTypes.DEFAULT_TYPE):
    message, doc, client = update.message, update.message.document, context.bot_data['gemini_client']
    if doc.file_size > 50 * 1024 * 1024: return await message.reply_text("‚ùå –§–∞–π–ª —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π (> 50 MB).")
    if doc.mime_type and doc.mime_type.startswith("audio/"): return await handle_audio(update, context, doc)
    await message.reply_text(f"–ó–∞–≥—Ä—É–∂–∞—é –¥–æ–∫—É–º–µ–Ω—Ç '{doc.file_name}'...", reply_to_message_id=message.message_id)
    doc_file = await doc.get_file()
    doc_bytes = await doc_file.download_as_bytearray()
    file_part = await upload_and_wait_for_file(client, doc_bytes, doc.mime_type, doc.file_name or "document")
    await handle_media_request(update, context, file_part, message.caption or "–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —ç—Ç–æ—Ç —Ñ–∞–π–ª.")

async def handle_video(update: Update, context: ContextTypes.DEFAULT_TYPE):
    message, video, client = update.message, update.message.video, context.bot_data['gemini_client']
    if video.file_size > 50 * 1024 * 1024: return await message.reply_text("‚ùå –í–∏–¥–µ–æ—Ñ–∞–π–ª —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π (> 50 MB).")
    await message.reply_text("–ó–∞–≥—Ä—É–∂–∞—é –≤–∏–¥–µ–æ...", reply_to_message_id=message.message_id)
    video_file = await video.get_file()
    video_bytes = await video_file.download_as_bytearray()
    video_part = await upload_and_wait_for_file(client, video_bytes, video.mime_type, video.file_name or "video.mp4")
    await handle_media_request(update, context, video_part, message.caption or "–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —ç—Ç–æ—Ç —Ñ–∞–π–ª.")

async def handle_audio(update: Update, context: ContextTypes.DEFAULT_TYPE, audio_source=None):
    message, client = update.message, context.bot_data['gemini_client']
    audio = audio_source or message.audio or message.voice
    if not audio: return
    file_name = getattr(audio, 'file_name', 'voice_message.ogg')
    user_text = message.caption or "–¢–≤–æ—è –≥–ª–∞–≤–Ω–∞—è –∑–∞–¥–∞—á–∞ ‚Äî –ø–æ–Ω—è—Ç—å —Å—É—Ç—å –∏ –æ—Ç–≤–µ—Ç–∏—Ç—å —Å–æ–¥–µ—Ä–∂–∞—Ç–µ–ª—å–Ω–æ. –ï—Å–ª–∏ –≤ –∞—É–¥–∏–æ –µ—Å—Ç—å –ø—Ä—è–º–æ–π –≤–æ–ø—Ä–æ—Å, –æ—Ç–≤–µ—Ç—å –Ω–∞ –Ω–µ–≥–æ. –ï—Å–ª–∏ —ç—Ç–æ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–µ –∏–ª–∏ –∏—Å—Ç–æ—Ä–∏—è, –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –µ–µ –∏ –ø–æ–¥–µ–ª–∏—Å—å —Å–≤–æ–∏–º –º–Ω–µ–Ω–∏–µ–º –∏–ª–∏ –∫–ª—é—á–µ–≤—ã–º–∏ –≤—ã–≤–æ–¥–∞–º–∏. –ü—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–π –ø–æ–ª–Ω—É—é —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—é —Ç–æ–ª—å–∫–æ –≤ —Ç–æ–º —Å–ª—É—á–∞–µ, –µ—Å–ª–∏ —Ç–µ–±—è –æ–± —ç—Ç–æ–º –ø–æ–ø—Ä–æ—Å—è—Ç –Ω–∞–ø—Ä—è–º—É—é —Å–ª–æ–≤–∞–º–∏ '—Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç', '—Ä–∞—Å—à–∏—Ñ—Ä—É–π' –∏–ª–∏ '–¥–æ—Å–ª–æ–≤–Ω–æ'."
    audio_file = await audio.get_file()
    audio_bytes = await audio_file.download_as_bytearray()
    audio_part = await upload_and_wait_for_file(client, audio_bytes, audio.mime_type, file_name)
    await handle_media_request(update, context, audio_part, user_text)

async def handle_youtube_url(update: Update, context: ContextTypes.DEFAULT_TYPE):
    message, text = update.message, update.message.text or ""
    match = re.search(YOUTUBE_REGEX, text)
    if not match: return
    youtube_url = f"https://www.youtube.com/watch?v={match.group(1)}"
    await message.reply_text("–ê–Ω–∞–ª–∏–∑–∏—Ä—É—é –≤–∏–¥–µ–æ —Å YouTube...", reply_to_message_id=message.message_id)
    youtube_part = types.Part(file_data=types.FileData(mime_type="video/youtube", file_uri=youtube_url))
    user_prompt = text.replace(match.group(0), "").strip() or "–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —ç—Ç–æ –≤–∏–¥–µ–æ."
    await handle_media_request(update, context, youtube_part, user_prompt)

async def handle_url(update: Update, context: ContextTypes.DEFAULT_TYPE):
    context.chat_data.pop('last_media_context', None)
    context.chat_data.pop('media_contexts', None)
    await process_request(update, context, [types.Part(text=update.message.text)])

async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    message, text = update.message, (update.message.text or "").strip()
    if not text: return
    context.chat_data['id'] = message.chat_id
    
    content_parts = [types.Part(text=text)]
    is_media_follow_up = False
    
    if message.reply_to_message:
        media_context = find_media_context_in_history(context, message.reply_to_message.message_id)
        if media_context:
            media_part = dict_to_part(media_context)
            if media_part:
                content_parts.insert(0, media_part)
                is_media_follow_up = True
                logger.info(f"–ü—Ä–∏–º–µ–Ω–µ–Ω –Ø–í–ù–´–ô –º–µ–¥–∏–∞-–∫–æ–Ω—Ç–µ–∫—Å—Ç (—á–µ—Ä–µ–∑ reply) –¥–ª—è —á–∞—Ç–∞ {message.chat_id}")

    if not is_media_follow_up:
        last_media_context_dict = context.chat_data.get('last_media_context')
        if last_media_context_dict:
            media_part = dict_to_part(last_media_context_dict)
            if media_part:
                content_parts.insert(0, media_part)
                is_media_follow_up = True
                logger.info(f"–ü—Ä–∏–º–µ–Ω–µ–Ω –ù–ï–Ø–í–ù–´–ô '–ª–∏–ø–∫–∏–π' –º–µ–¥–∏–∞-–∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è —á–∞—Ç–∞ {message.chat_id}")

    await process_request(update, context, content_parts, is_media_request=is_media_follow_up)

# --- –ó–ê–ü–£–°–ö –ë–û–¢–ê ---
async def handle_telegram_webhook(request: aiohttp.web.Request) -> aiohttp.web.Response:
    application = request.app['bot_app']
    try:
        data = await request.json(); update = Update.de_json(data, application.bot)
        await application.process_update(update)
        return aiohttp.web.Response(status=200)
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤–µ–±—Ö—É–∫–∞: {e}", exc_info=True)
        return aiohttp.web.Response(status=500)

async def run_web_server(application: Application, stop_event: asyncio.Event):
    app = aiohttp.web.Application()
    app['bot_app'] = application
    app.router.add_post('/' + GEMINI_WEBHOOK_PATH.strip('/'), handle_telegram_webhook)
    runner = aiohttp.web.AppRunner(app)
    await runner.setup()
    site = aiohttp.web.TCPSite(runner, '0.0.0.0', int(os.getenv("PORT", "10000")))
    await site.start()
    logger.info(f"–í–µ–±-—Å–µ—Ä–≤–µ—Ä –∑–∞–ø—É—â–µ–Ω –Ω–∞ –ø–æ—Ä—Ç—É {os.getenv('PORT', '10000')}")
    await stop_event.wait()
    await runner.cleanup()
    
async def main():
    persistence = PostgresPersistence(DATABASE_URL) if DATABASE_URL else None
    builder = Application.builder().token(TELEGRAM_BOT_TOKEN)
    if persistence: builder.persistence(persistence)
    application = builder.build()
    
    await application.initialize()
    application.bot_data['gemini_client'] = genai.Client(api_key=GOOGLE_API_KEY)
    
    commands = [
        BotCommand("start", "–ò–Ω—Ñ–æ –∏ –Ω–∞—á–∞–ª–æ —Ä–∞–±–æ—Ç—ã"),
        BotCommand("config", "–ù–∞—Å—Ç—Ä–æ–∏—Ç—å —Ä–µ–∂–∏–º –∏ –ø–æ–∏—Å–∫"),
        BotCommand("transcript", "–¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è –º–µ–¥–∏–∞ (–æ—Ç–≤–µ—Ç–æ–º)"),
        BotCommand("summarize", "–ö—Ä–∞—Ç–∫–∏–π –ø–µ—Ä–µ—Å–∫–∞–∑ (–æ—Ç–≤–µ—Ç–æ–º)"),
        BotCommand("keypoints", "–ö–ª—é—á–µ–≤—ã–µ —Ç–µ–∑–∏—Å—ã (–æ—Ç–≤–µ—Ç–æ–º)"),
        BotCommand("newtopic", "–°–±—Ä–æ—Å–∏—Ç—å –∫–æ–Ω—Ç–µ–∫—Å—Ç —Ñ–∞–π–ª–æ–≤"),
        BotCommand("clear", "–û—á–∏—Å—Ç–∏—Ç—å –≤—Å—é –∏—Å—Ç–æ—Ä–∏—é —á–∞—Ç–∞")
    ]
    application.add_handler(CommandHandler("start", start_command))
    application.add_handler(CommandHandler("config", config_command))
    application.add_handler(CommandHandler("clear", clear_command))
    application.add_handler(CommandHandler("transcript", transcript_command))
    application.add_handler(CommandHandler("summarize", summarize_command))
    application.add_handler(CommandHandler("keypoints", keypoints_command))
    application.add_handler(CommandHandler("newtopic", newtopic_command))
    application.add_handler(CallbackQueryHandler(config_callback))
    
    application.add_handler(MessageHandler(filters.PHOTO, handle_photo))
    application.add_handler(MessageHandler(filters.VIDEO, handle_video))
    application.add_handler(MessageHandler(filters.VOICE, handle_audio))
    application.add_handler(MessageHandler(filters.AUDIO, handle_audio))
    application.add_handler(MessageHandler(filters.Document.ALL, handle_document))
    application.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND & filters.Regex(YOUTUBE_REGEX), handle_youtube_url))
    application.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND & filters.Regex(URL_REGEX), handle_url))
    application.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))
    
    await application.bot.set_my_commands(commands)
    
    stop_event = asyncio.Event()
    loop = asyncio.get_running_loop()
    for sig in (signal.SIGINT, signal.SIGTERM): loop.add_signal_handler(sig, stop_event.set)
    try:
        webhook_url = f"{WEBHOOK_HOST.rstrip('/')}/{GEMINI_WEBHOOK_PATH.strip('/')}"
        await application.bot.set_webhook(url=webhook_url, allowed_updates=Update.ALL_TYPES)
        logger.info(f"–í–µ–±—Ö—É–∫ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –Ω–∞: {webhook_url}")
        await run_web_server(application, stop_event)
    finally:
        logger.info("–ù–∞—á–∞–ª–æ —à—Ç–∞—Ç–Ω–æ–π –æ—Å—Ç–∞–Ω–æ–≤–∫–∏...")
        if persistence: persistence.close()
        logger.info("–ü—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –ø–æ–ª–Ω–æ—Å—Ç—å—é –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ.")

if __name__ == '__main__':
    asyncio.run(main())
